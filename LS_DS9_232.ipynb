{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS9_232.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikibhatt/DS-Unit-2-Applied-Modeling/blob/master/LS_DS9_232.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U2ha9OWxf0jw"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 3, Module 2*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-hTictxWYih7"
      },
      "source": [
        "# Permutation & Boosting\n",
        "\n",
        "- Get **permutation importances** for model interpretation and feature selection\n",
        "- Use xgboost for **gradient boosting**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LoxNYFBXYih9"
      },
      "source": [
        "### Default Feature Importances are fast, but Permutation Importances may be more accurate\n",
        "\n",
        "- Permutation Importances\n",
        "  - [Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)\n",
        "  - [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
        "- (Default) Feature Importances\n",
        "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
        "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "\n",
        "### Try Tree Ensembles when you do machine learning with labeled, tabular data\n",
        "- \"Tree Ensembles\" means Random Forest or **Gradient Boosting** models. \n",
        "- [Tree Ensembles often have the best predictive accuracy](https://arxiv.org/abs/1708.05070) with labeled, tabular data.\n",
        "- Why? Because trees can fit non-linear, non-[monotonic](https://en.wikipedia.org/wiki/Monotonic_function) relationships, and [interactions](https://christophm.github.io/interpretable-ml-book/interaction.html) between features.\n",
        "- A single decision tree, grown to unlimited depth, will [overfit](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/). We solve this problem by ensembling trees, with bagging (Random Forest) or **[boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw)** (Gradient Boosting).\n",
        "- Random Forest's advantage: may be less sensitive to hyperparameters. **Gradient Boosting's advantage:** may get better predictive accuracy.\n",
        "\n",
        "#### Python libraries for Gradient Boosting\n",
        "- [scikit-learn Gradient Tree Boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting) — slower than other libraries, but [the new version may be better](https://twitter.com/amuellerml/status/1129443826945396737)\n",
        "  - Anaconda: already installed\n",
        "  - Google Colab: already installed\n",
        "- [xgboost](https://xgboost.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://xiaoxiaowang87.github.io/monotonicity_constraint/)\n",
        "  - Anaconda, Mac/Linux: `conda install -c conda-forge xgboost`\n",
        "  - Windows: `conda install -c anaconda py-xgboost`\n",
        "  - Google Colab: already installed\n",
        "- [LightGBM](https://lightgbm.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://blog.datadive.net/monotonicity-constraints-in-machine-learning/)\n",
        "  - Anaconda: `conda install -c conda-forge lightgbm`\n",
        "  - Google Colab: already installed\n",
        "- [CatBoost](https://catboost.ai/) — can accept missing values and use [categorical features](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html) without preprocessing\n",
        "  - Anaconda: `conda install -c conda-forge catboost`\n",
        "  - Google Colab: `pip install catboost`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wMejJg0w8v76"
      },
      "source": [
        "### Setup\n",
        "\n",
        "Run the code cell below. You can work locally (follow the [local setup instructions](https://lambdaschool.github.io/ds/unit2/local/)) or on Colab.\n",
        "\n",
        "Libraries:\n",
        "\n",
        "- category_encoders\n",
        "- [**eli5**](https://eli5.readthedocs.io/en/latest/)\n",
        "- matplotlib\n",
        "- numpy\n",
        "- pandas\n",
        "- scikit-learn\n",
        "- [**xgboost**](https://xgboost.readthedocs.io/en/latest/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BFQMky3CYih-",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "    !pip install eli5\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z-TExplb_Slf",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Merge train_features.csv & train_labels.csv\n",
        "train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
        "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n",
        "\n",
        "# Read test_features.csv & sample_submission.csv\n",
        "test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
        "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')\n",
        "\n",
        "\n",
        "# Split train into train & val\n",
        "train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
        "                              stratify=train['status_group'], random_state=42)\n",
        "\n",
        "\n",
        "def wrangle(X):\n",
        "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # About 3% of the time, latitude has small values near zero,\n",
        "    # outside Tanzania, so we'll treat these values like zero.\n",
        "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
        "    \n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    # Also create a \"missing indicator\" column, because the fact that\n",
        "    # values are missing may be a predictive signal.\n",
        "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
        "                       'gps_height', 'population']\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "        X[col+'_MISSING'] = X[col].isnull()\n",
        "            \n",
        "    # Drop duplicate columns\n",
        "    duplicates = ['quantity_group', 'payment_type']\n",
        "    X = X.drop(columns=duplicates)\n",
        "    \n",
        "    # Drop recorded_by (never varies) and id (always varies, random)\n",
        "    unusable_variance = ['recorded_by', 'id']\n",
        "    X = X.drop(columns=unusable_variance)\n",
        "    \n",
        "    # Convert date_recorded to datetime\n",
        "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
        "    \n",
        "    # Extract components from date_recorded, then drop the original column\n",
        "    X['year_recorded'] = X['date_recorded'].dt.year\n",
        "    X['month_recorded'] = X['date_recorded'].dt.month\n",
        "    X['day_recorded'] = X['date_recorded'].dt.day\n",
        "    X = X.drop(columns='date_recorded')\n",
        "    \n",
        "    # Engineer feature: how many years from construction_year to date_recorded\n",
        "    X['years'] = X['year_recorded'] - X['construction_year']\n",
        "    X['years_MISSING'] = X['years'].isnull()\n",
        "    \n",
        "    # return the wrangled dataframe\n",
        "    return X\n",
        "\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rhg8PQKt_jzP",
        "colab": {}
      },
      "source": [
        "# Arrange data into X features matrix and y target vector\n",
        "target = 'status_group'\n",
        "X_train = train.drop(columns=target)\n",
        "y_train = train[target]\n",
        "X_val = val.drop(columns=target)\n",
        "y_val = val[target]\n",
        "X_test = test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m8lB4z5l_eml",
        "outputId": "08c74725-970c-44d3-a618-78fda7bad6b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8135521885521886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7HOayKBOYiit"
      },
      "source": [
        "# 3 types of feature importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4bRhsxENYiiu"
      },
      "source": [
        "## 1. (Default) Feature Importances\n",
        "\n",
        "Fastest, good for first estimates, but be aware:\n",
        "\n",
        "\n",
        "\n",
        ">**When the dataset has two (or more) correlated features, then from the point of view of the model, any of these correlated features can be used as the predictor, with no concrete preference of one over the others.** But once one of them is used, the importance of others is significantly reduced since effectively the impurity they can remove is already removed by the first feature. As a consequence, they will have a lower reported importance. This is not an issue when we want to use feature selection to reduce overfitting, since it makes sense to remove features that are mostly duplicated by other features. But when interpreting the data, it can lead to the incorrect conclusion that one of the variables is a strong predictor while the others in the same group are unimportant, while actually they are very close in terms of their relationship with the response variable. — [Selecting good features – Part III: random forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/) \n",
        "\n",
        "\n",
        " \n",
        " > **The scikit-learn Random Forest feature importance ... tends to inflate the importance of continuous or high-cardinality categorical variables.** ... Breiman and Cutler, the inventors of Random Forests, indicate that this method of “adding up the gini decreases for each individual variable over all trees in the forest gives a **fast** variable importance that is often very consistent with the permutation importance measure.” —  [Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BNVm6f7mYiiu",
        "outputId": "ac8e959d-e28c-4c16-81e7-84dde50bb76b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "# Get feature importances\n",
        "rf = pipeline.named_steps['randomforestclassifier']\n",
        "importances = pd.Series(rf.feature_importances_, X_train.columns)\n",
        "\n",
        "# Plot feature importances\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 20\n",
        "plt.figure(figsize=(10,n/2))\n",
        "plt.title(f'Top {n} features')\n",
        "importances.sort_values()[-n:].plot.barh(color='grey');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArYAAAJOCAYAAABCwkSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRvmFtOoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y8HzLcCBYiiv"
      },
      "source": [
        "## 2. Drop-Column Importance\n",
        "\n",
        "The best in theory, but too slow in practice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DQAOlERnYiiw",
        "outputId": "aa25edfd-4c7f-48c7-e03a-5977c58e9b05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "column  = 'wpt_name'\n",
        "\n",
        "# Fit without column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train.drop(columns=column), y_train)\n",
        "score_without = pipeline.score(X_val.drop(columns=column), y_val)\n",
        "print(f'Validation Accuracy without {column}: {score_without}')\n",
        "\n",
        "# Fit with column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train, y_train)\n",
        "score_with = pipeline.score(X_val, y_val)\n",
        "print(f'Validation Accuracy with {column}: {score_with}')\n",
        "\n",
        "# Compare the error with & without column\n",
        "print(f'Drop-Column Importance for {column}: {score_with - score_without}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy without wpt_name: 0.8087542087542088\n",
            "Validation Accuracy with wpt_name: 0.8135521885521886\n",
            "Drop-Column Importance for wpt_name: 0.004797979797979801\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Vu39wGkYiix"
      },
      "source": [
        "## 3. Permutation Importance\n",
        "\n",
        "Permutation Importance is a good compromise between Feature Importance based on impurity reduction (which is the fastest) and Drop Column Importance (which is the \"best.\")\n",
        "\n",
        "[The ELI5 library documentation explains,](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html)\n",
        "\n",
        "> Importance can be measured by looking at how much the score (accuracy, F1, R^2, etc. - any score we’re interested in) decreases when a feature is not available.\n",
        ">\n",
        "> To do that one can remove feature from the dataset, re-train the estimator and check the score. But it requires re-training an estimator for each feature, which can be computationally intensive. ...\n",
        ">\n",
        ">To avoid re-training the estimator we can remove a feature only from the test part of the dataset, and compute score without using this feature. It doesn’t work as-is, because estimators expect feature to be present. So instead of removing a feature we can replace it with random noise - feature column is still there, but it no longer contains useful information. This method works if noise is drawn from the same distribution as original feature values (as otherwise estimator may fail). The simplest way to get such noise is to shuffle values for a feature, i.e. use other examples’ feature values - this is how permutation importance is computed.\n",
        ">\n",
        ">The method is most suitable for computing feature importances when a number of columns (features) is not huge; it can be resource-intensive otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GYCiEx7zYiiy"
      },
      "source": [
        "### Do-It-Yourself way, for intuition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TksOf_n2Yiiy",
        "outputId": "29bddaff-4a22-4745-b99a-4fd9e8a0cf32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# BEFORE: Sequence of the feature to be permuted\n",
        "feature = 'quantity'\n",
        "X_val[feature].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3290     insufficient\n",
              "47666    insufficient\n",
              "2538           enough\n",
              "53117          enough\n",
              "51817          enough\n",
              "Name: quantity, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-kUNXTmtpZ_",
        "colab_type": "code",
        "outputId": "ef7111a3-7c8f-4827-8718-6265c2706ec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# BEFORE: Distribution of the feature to be permuted\n",
        "X_val[feature].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "enough          6619\n",
              "insufficient    2976\n",
              "dry             1325\n",
              "seasonal         806\n",
              "unknown          154\n",
              "Name: quantity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvMNON5dtzqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PERMUTE!\n",
        "X_val_permuted = X_val.copy()\n",
        "X_val_permuted[feature] = np.random.permutation(X_val[feature])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVEM1qRCuJtG",
        "colab_type": "code",
        "outputId": "c2315a2d-699a-4983-faaa-89c13c884c0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# AFTER: Sequence has changed\n",
        "X_val_permuted[feature].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3290     insufficient\n",
              "47666             dry\n",
              "2538           enough\n",
              "53117          enough\n",
              "51817          enough\n",
              "Name: quantity, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfp-O3ZouPbo",
        "colab_type": "code",
        "outputId": "10c1651c-55d4-4bb0-915a-0a0acd1a98a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# AFTER: Distribution hasn't changed!\n",
        "X_val_permuted[feature].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "enough          6619\n",
              "insufficient    2976\n",
              "dry             1325\n",
              "seasonal         806\n",
              "unknown          154\n",
              "Name: quantity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NR2979iujS2",
        "colab_type": "code",
        "outputId": "b866af54-47d0-403a-9e33-7ed79f82d10f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Get the permutation importance\n",
        "# Notice that we don't need to refit the pipeline here!\n",
        "score_permuted = pipeline.score(X_val_permuted, y_val)\n",
        "\n",
        "print(f'Validation accuracy with {feature}: {score_with}')\n",
        "print(f'Validation accuracy with {feature} permuted: {score_permuted}')\n",
        "print(f'Permutation importance: {score_with - score_permuted}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy with quantity: 0.8135521885521886\n",
            "Validation accuracy with quantity permuted: 0.7095959595959596\n",
            "Permutation importance: 0.10395622895622902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR2Ii8Nsu5By",
        "colab_type": "code",
        "outputId": "8b9ea35a-3461-49dc-ea46-9e2cb07433f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Rerun the permutation importance process, but for a different feature\n",
        "feature = 'wpt_name'\n",
        "X_val_permuted = X_val.copy()\n",
        "X_val_permuted[feature] = np.random.permutation(X_val[feature])\n",
        "score_permuted = pipeline.score(X_val_permuted, y_val)\n",
        "\n",
        "print(f'Validation accuracy with {feature}: {score_with}')\n",
        "print(f'Validation accuracy with {feature} permuted: {score_permuted}')\n",
        "print(f'Permutation importance: {score_with - score_permuted}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy with wpt_name: 0.8135521885521886\n",
            "Validation accuracy with wpt_name permuted: 0.811952861952862\n",
            "Permutation importance: 0.0015993265993266004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0LYk19SNYii7"
      },
      "source": [
        "### With eli5 library\n",
        "\n",
        "For more documentation on using this library, see:\n",
        "- [eli5.sklearn.PermutationImportance](https://eli5.readthedocs.io/en/latest/autodocs/sklearn.html#eli5.sklearn.permutation_importance.PermutationImportance)\n",
        "- [eli5.show_weights](https://eli5.readthedocs.io/en/latest/autodocs/eli5.html#eli5.show_weights)\n",
        "- [scikit-learn user guide, `scoring` parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules)\n",
        "\n",
        "eli5 doesn't work with pipelines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hpSemTkFFP8i",
        "outputId": "0b3e4030-05ec-4b9d-ec9f-2edf58fc340b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "transformers = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median')\n",
        ")\n",
        "\n",
        "X_train_transformed = transformers.fit_transform(X_train)\n",
        "X_val_transformed = transformers.transform(X_val)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "model.fit(X_train_transformed, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blJ_VWSrwcpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "permuter = PermutationImportance(\n",
        "    model, \n",
        "    scoring='accuracy', \n",
        "    n_iter=5, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "permuter.fit(X_val_transformed, y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkz3By1ixOgD",
        "colab_type": "code",
        "outputId": "4e8b77fc-fef9-4a38-d7a3-b43e9a8de0a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        }
      },
      "source": [
        "feature_names = X_val.columns.tolist()\n",
        "pd.Series(permuter.feature_importances_, feature_names).sort_values(ascending=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "quantity                     0.101633\n",
              "amount_tsh                   0.010758\n",
              "waterpoint_type              0.010354\n",
              "extraction_type_class        0.010168\n",
              "longitude                    0.008838\n",
              "waterpoint_type_group        0.006751\n",
              "population                   0.006414\n",
              "latitude                     0.006246\n",
              "payment                      0.003064\n",
              "subvillage                   0.003030\n",
              "years                        0.002980\n",
              "public_meeting               0.002963\n",
              "construction_year            0.002609\n",
              "district_code                0.002239\n",
              "extraction_type_group        0.001785\n",
              "gps_height                   0.001768\n",
              "source                       0.001549\n",
              "day_recorded                 0.001498\n",
              "funder                       0.001128\n",
              "month_recorded               0.001128\n",
              "wpt_name                     0.000943\n",
              "region                       0.000926\n",
              "region_code                  0.000892\n",
              "longitude_MISSING            0.000875\n",
              "scheme_name                  0.000808\n",
              "permit                       0.000774\n",
              "lga                          0.000724\n",
              "scheme_management            0.000657\n",
              "ward                         0.000539\n",
              "water_quality                0.000539\n",
              "extraction_type              0.000539\n",
              "years_MISSING                0.000471\n",
              "management                   0.000455\n",
              "num_private                  0.000337\n",
              "source_class                 0.000337\n",
              "year_recorded                0.000269\n",
              "population_MISSING           0.000202\n",
              "latitude_MISSING             0.000135\n",
              "gps_height_MISSING           0.000051\n",
              "construction_year_MISSING    0.000051\n",
              "source_type                 -0.000017\n",
              "installer                   -0.000051\n",
              "management_group            -0.000488\n",
              "quality_group               -0.000572\n",
              "basin                       -0.001431\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcObfkqjxqmE",
        "colab_type": "code",
        "outputId": "35d9243b-520a-4253-b3c8-ed532017b508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        }
      },
      "source": [
        "feature_names = X_val.columns.tolist()\n",
        "\n",
        "eli5.show_weights(\n",
        "    permuter,\n",
        "    top=None, # show permutation importances for all features\n",
        "    feature_names=feature_names\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.1016\n",
              "                \n",
              "                    &plusmn; 0.0029\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.85%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0108\n",
              "                \n",
              "                    &plusmn; 0.0024\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                amount_tsh\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.96%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0104\n",
              "                \n",
              "                    &plusmn; 0.0018\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                waterpoint_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.01%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0102\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type_class\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.38%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0088\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                longitude\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0068\n",
              "                \n",
              "                    &plusmn; 0.0018\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                waterpoint_type_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.11%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0064\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                population\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.16%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0062\n",
              "                \n",
              "                    &plusmn; 0.0026\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                latitude\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.28%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0031\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                payment\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.29%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0030\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                subvillage\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.31%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0030\n",
              "                \n",
              "                    &plusmn; 0.0026\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                years\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.32%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0030\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                public_meeting\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.46%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0026\n",
              "                \n",
              "                    &plusmn; 0.0029\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                construction_year\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.62%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0022\n",
              "                \n",
              "                    &plusmn; 0.0016\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                district_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.82%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0018\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.83%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0018\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                gps_height\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.93%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0015\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.96%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0015\n",
              "                \n",
              "                    &plusmn; 0.0017\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                day_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.14%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0011\n",
              "                \n",
              "                    &plusmn; 0.0012\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                funder\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.14%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0011\n",
              "                \n",
              "                    &plusmn; 0.0019\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                month_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.24%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0014\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                wpt_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.25%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                region\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.27%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0014\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                region_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.28%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                longitude_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.32%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0020\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                scheme_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.34%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                permit\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.37%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0009\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                lga\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.41%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0020\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                scheme_management\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.49%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0017\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                ward\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.49%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                water_quality\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.49%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0014\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.53%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                years_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.55%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0021\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                management\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.63%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                num_private\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.63%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source_class\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.69%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                year_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.74%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                population_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.81%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                latitude_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.90%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                gps_height_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.90%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                construction_year_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.95%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0000\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.90%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0001\n",
              "                \n",
              "                    &plusmn; 0.0020\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                installer\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.52%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0005\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                management_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.47%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0006\n",
              "                \n",
              "                    &plusmn; 0.0012\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quality_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 98.99%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0014\n",
              "                \n",
              "                    &plusmn; 0.0009\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                basin\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q07yW9k-Yii8"
      },
      "source": [
        "### We can use importances for feature selection\n",
        "\n",
        "For example, we can remove features with zero importance. The model trains faster and the score does not decrease."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7JnE85o00Hi",
        "colab_type": "code",
        "outputId": "b52686fd-5440-4d45-b52e-86b6921420d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('Shape before removing features:', X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape before removing features: (47520, 45)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tZrPFyEMYii9",
        "colab": {}
      },
      "source": [
        "minimum_importance = 0\n",
        "mask = permuter.feature_importances_ > minimum_importance\n",
        "features = X_train.columns[mask]\n",
        "X_train = X_train[features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78HliaiH1sw8",
        "colab_type": "code",
        "outputId": "3b788e38-cdf6-421f-db6e-8d2d4b9a7e54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('Shape after removing features:', X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape after removing features: (47520, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blPqN1kQ1x5V",
        "colab_type": "code",
        "outputId": "9941bc18-ae5a-41e3-b9a8-8d24cd4074de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_val = X_val[features]\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8117003367003367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fl67bCR7WY6j"
      },
      "source": [
        "## Use xgboost for gradient boosting\n",
        "\n",
        "#### [XGBoost Python API Reference: Scikit-Learn API](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wsnJRKjfWYph",
        "outputId": "8ad320c1-71cb-4fdc-e48c-b8b018bf300b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('ordinalencoder',\n",
              "                 OrdinalEncoder(cols=['funder', 'wpt_name', 'subvillage',\n",
              "                                      'region', 'lga', 'ward', 'public_meeting',\n",
              "                                      'scheme_management', 'scheme_name',\n",
              "                                      'permit', 'extraction_type',\n",
              "                                      'extraction_type_group',\n",
              "                                      'extraction_type_class', 'management',\n",
              "                                      'payment', 'water_quality', 'quantity',\n",
              "                                      'source', 'source_class',\n",
              "                                      'waterpoint_type',\n",
              "                                      'waterpoin...\n",
              "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                               colsample_bylevel=1, colsample_bynode=1,\n",
              "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
              "                               max_delta_step=0, max_depth=3,\n",
              "                               min_child_weight=1, missing=None,\n",
              "                               n_estimators=100, n_jobs=-1, nthread=None,\n",
              "                               objective='multi:softprob', random_state=42,\n",
              "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                               seed=None, silent=None, subsample=1,\n",
              "                               verbosity=1))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcW9_ZdD3Ztb",
        "colab_type": "code",
        "outputId": "fa639efd-cc34-4173-8b21-f06950f5d8c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = pipeline.predict(X_val)\n",
        "print('Validation Accuracy', accuracy_score(y_val, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7457070707070707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ubb7Ot6OZcK1"
      },
      "source": [
        "### Understand the difference between boosting & bagging\n",
        "\n",
        "Boosting (used by Gradient Boosting) is different than Bagging (used by Random Forests). \n",
        "\n",
        "[_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8.2.3, Boosting:\n",
        "\n",
        ">Recall that bagging involves creating multiple copies of the original training data set using the bootstrap, fitting a separate decision tree to each copy, and then combining all of the trees in order to create a single predictive model.\n",
        ">\n",
        ">**Boosting works in a similar way, except that the trees are grown _sequentially_: each tree is grown using information from previously grown trees.**\n",
        ">\n",
        ">Unlike fitting a single large decision tree to the data, which amounts to _fitting the data hard_ and potentially overfitting, the boosting approach instead _learns slowly._ Given the current model, we fit a decision tree to the residuals from the model.\n",
        ">\n",
        ">We then add this new decision tree into the fitted function in order to update the residuals. Each of these trees can be rather small, with just a few terminal nodes. **By fitting small trees to the residuals, we slowly improve fˆ in areas where it does not perform well.**\n",
        ">\n",
        ">Note that in boosting, unlike in bagging, the construction of each tree depends strongly on the trees that have already been grown."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eCjVSlD_XJr2"
      },
      "source": [
        "#### [Avoid Overfitting By Early Stopping With XGBoost In Python](https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/)\n",
        "\n",
        "Why is early stopping better than a For loop, or GridSearchCV, to optimize `n_estimators`?\n",
        "\n",
        "With early stopping, if `n_iterations` is our number of iterations, then we fit `n_iterations` decision trees.\n",
        "\n",
        "With a for loop, or GridSearchCV, we'd fit `sum(range(1,n_rounds+1))` trees.\n",
        "\n",
        "But it doesn't work well with pipelines. You may need to re-run multiple times with different values of other parameters such as `max_depth` and `learning_rate`.\n",
        "\n",
        "#### XGBoost parameters\n",
        "- [Notes on parameter tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html)\n",
        "- [Parameters documentation](https://xgboost.readthedocs.io/en/latest/parameter.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZNX3IKftXBFS",
        "outputId": "27c3c976-d163-419d-d8da-edeac62170c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "encoder = ce.OrdinalEncoder()\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_val_encoded = encoder.transform(X_val)\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=1000, # <= 1000 trees, depends on early stopping\n",
        "    max_depth=7,       # try deeper trees because of high cardinality categoricals\n",
        "    learning_rate=0.5, # try higher learning rate\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "eval_set = [(X_train_encoded, y_train), \n",
        "            (X_val_encoded, y_val)]\n",
        "\n",
        "model.fit(X_train_encoded, y_train, \n",
        "          eval_set=eval_set, \n",
        "          eval_metric='merror', \n",
        "          early_stopping_rounds=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-merror:0.250884\tvalidation_1-merror:0.261953\n",
            "Multiple eval metrics have been passed: 'validation_1-merror' will be used for early stopping.\n",
            "\n",
            "Will train until validation_1-merror hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-merror:0.234722\tvalidation_1-merror:0.245791\n",
            "[2]\tvalidation_0-merror:0.229903\tvalidation_1-merror:0.242424\n",
            "[3]\tvalidation_0-merror:0.225358\tvalidation_1-merror:0.2383\n",
            "[4]\tvalidation_0-merror:0.216372\tvalidation_1-merror:0.233249\n",
            "[5]\tvalidation_0-merror:0.209343\tvalidation_1-merror:0.229714\n",
            "[6]\tvalidation_0-merror:0.204714\tvalidation_1-merror:0.22601\n",
            "[7]\tvalidation_0-merror:0.198927\tvalidation_1-merror:0.221549\n",
            "[8]\tvalidation_0-merror:0.194613\tvalidation_1-merror:0.22037\n",
            "[9]\tvalidation_0-merror:0.191793\tvalidation_1-merror:0.220286\n",
            "[10]\tvalidation_0-merror:0.189078\tvalidation_1-merror:0.218603\n",
            "[11]\tvalidation_0-merror:0.18609\tvalidation_1-merror:0.217256\n",
            "[12]\tvalidation_0-merror:0.182618\tvalidation_1-merror:0.216919\n",
            "[13]\tvalidation_0-merror:0.180051\tvalidation_1-merror:0.215825\n",
            "[14]\tvalidation_0-merror:0.177083\tvalidation_1-merror:0.213973\n",
            "[15]\tvalidation_0-merror:0.174474\tvalidation_1-merror:0.214394\n",
            "[16]\tvalidation_0-merror:0.173338\tvalidation_1-merror:0.213721\n",
            "[17]\tvalidation_0-merror:0.171612\tvalidation_1-merror:0.214141\n",
            "[18]\tvalidation_0-merror:0.168981\tvalidation_1-merror:0.211616\n",
            "[19]\tvalidation_0-merror:0.166604\tvalidation_1-merror:0.211279\n",
            "[20]\tvalidation_0-merror:0.165846\tvalidation_1-merror:0.210606\n",
            "[21]\tvalidation_0-merror:0.164878\tvalidation_1-merror:0.209343\n",
            "[22]\tvalidation_0-merror:0.1629\tvalidation_1-merror:0.209175\n",
            "[23]\tvalidation_0-merror:0.159301\tvalidation_1-merror:0.207492\n",
            "[24]\tvalidation_0-merror:0.15705\tvalidation_1-merror:0.208754\n",
            "[25]\tvalidation_0-merror:0.154167\tvalidation_1-merror:0.206818\n",
            "[26]\tvalidation_0-merror:0.15202\tvalidation_1-merror:0.207744\n",
            "[27]\tvalidation_0-merror:0.1508\tvalidation_1-merror:0.207492\n",
            "[28]\tvalidation_0-merror:0.149095\tvalidation_1-merror:0.206818\n",
            "[29]\tvalidation_0-merror:0.148043\tvalidation_1-merror:0.206734\n",
            "[30]\tvalidation_0-merror:0.146528\tvalidation_1-merror:0.206902\n",
            "[31]\tvalidation_0-merror:0.145055\tvalidation_1-merror:0.206734\n",
            "[32]\tvalidation_0-merror:0.143182\tvalidation_1-merror:0.206397\n",
            "[33]\tvalidation_0-merror:0.141519\tvalidation_1-merror:0.20505\n",
            "[34]\tvalidation_0-merror:0.140341\tvalidation_1-merror:0.204545\n",
            "[35]\tvalidation_0-merror:0.138152\tvalidation_1-merror:0.204882\n",
            "[36]\tvalidation_0-merror:0.135417\tvalidation_1-merror:0.204461\n",
            "[37]\tvalidation_0-merror:0.134343\tvalidation_1-merror:0.203872\n",
            "[38]\tvalidation_0-merror:0.133081\tvalidation_1-merror:0.202862\n",
            "[39]\tvalidation_0-merror:0.132134\tvalidation_1-merror:0.202946\n",
            "[40]\tvalidation_0-merror:0.129966\tvalidation_1-merror:0.202862\n",
            "[41]\tvalidation_0-merror:0.128346\tvalidation_1-merror:0.202104\n",
            "[42]\tvalidation_0-merror:0.126999\tvalidation_1-merror:0.201347\n",
            "[43]\tvalidation_0-merror:0.126221\tvalidation_1-merror:0.201515\n",
            "[44]\tvalidation_0-merror:0.124011\tvalidation_1-merror:0.201178\n",
            "[45]\tvalidation_0-merror:0.122475\tvalidation_1-merror:0.200084\n",
            "[46]\tvalidation_0-merror:0.121338\tvalidation_1-merror:0.200253\n",
            "[47]\tvalidation_0-merror:0.120055\tvalidation_1-merror:0.200673\n",
            "[48]\tvalidation_0-merror:0.119087\tvalidation_1-merror:0.200758\n",
            "[49]\tvalidation_0-merror:0.117172\tvalidation_1-merror:0.201599\n",
            "[50]\tvalidation_0-merror:0.115804\tvalidation_1-merror:0.200842\n",
            "[51]\tvalidation_0-merror:0.114436\tvalidation_1-merror:0.201347\n",
            "[52]\tvalidation_0-merror:0.1129\tvalidation_1-merror:0.201431\n",
            "[53]\tvalidation_0-merror:0.111385\tvalidation_1-merror:0.201684\n",
            "[54]\tvalidation_0-merror:0.110017\tvalidation_1-merror:0.2\n",
            "[55]\tvalidation_0-merror:0.109343\tvalidation_1-merror:0.201178\n",
            "[56]\tvalidation_0-merror:0.108565\tvalidation_1-merror:0.200842\n",
            "[57]\tvalidation_0-merror:0.107407\tvalidation_1-merror:0.200673\n",
            "[58]\tvalidation_0-merror:0.106776\tvalidation_1-merror:0.200421\n",
            "[59]\tvalidation_0-merror:0.105871\tvalidation_1-merror:0.199663\n",
            "[60]\tvalidation_0-merror:0.105072\tvalidation_1-merror:0.200505\n",
            "[61]\tvalidation_0-merror:0.103683\tvalidation_1-merror:0.200673\n",
            "[62]\tvalidation_0-merror:0.102694\tvalidation_1-merror:0.200926\n",
            "[63]\tvalidation_0-merror:0.101052\tvalidation_1-merror:0.198653\n",
            "[64]\tvalidation_0-merror:0.100421\tvalidation_1-merror:0.200253\n",
            "[65]\tvalidation_0-merror:0.099432\tvalidation_1-merror:0.199747\n",
            "[66]\tvalidation_0-merror:0.096928\tvalidation_1-merror:0.200168\n",
            "[67]\tvalidation_0-merror:0.095981\tvalidation_1-merror:0.200589\n",
            "[68]\tvalidation_0-merror:0.094676\tvalidation_1-merror:0.200168\n",
            "[69]\tvalidation_0-merror:0.093813\tvalidation_1-merror:0.199495\n",
            "[70]\tvalidation_0-merror:0.092908\tvalidation_1-merror:0.19899\n",
            "[71]\tvalidation_0-merror:0.092466\tvalidation_1-merror:0.199579\n",
            "[72]\tvalidation_0-merror:0.09112\tvalidation_1-merror:0.198653\n",
            "[73]\tvalidation_0-merror:0.090088\tvalidation_1-merror:0.198822\n",
            "[74]\tvalidation_0-merror:0.08891\tvalidation_1-merror:0.197896\n",
            "[75]\tvalidation_0-merror:0.086848\tvalidation_1-merror:0.198822\n",
            "[76]\tvalidation_0-merror:0.08588\tvalidation_1-merror:0.199495\n",
            "[77]\tvalidation_0-merror:0.084806\tvalidation_1-merror:0.199579\n",
            "[78]\tvalidation_0-merror:0.083733\tvalidation_1-merror:0.199747\n",
            "[79]\tvalidation_0-merror:0.08287\tvalidation_1-merror:0.199663\n",
            "[80]\tvalidation_0-merror:0.081629\tvalidation_1-merror:0.200084\n",
            "[81]\tvalidation_0-merror:0.081313\tvalidation_1-merror:0.200253\n",
            "[82]\tvalidation_0-merror:0.080724\tvalidation_1-merror:0.199832\n",
            "[83]\tvalidation_0-merror:0.079461\tvalidation_1-merror:0.199832\n",
            "[84]\tvalidation_0-merror:0.078514\tvalidation_1-merror:0.200589\n",
            "[85]\tvalidation_0-merror:0.078051\tvalidation_1-merror:0.201094\n",
            "[86]\tvalidation_0-merror:0.077252\tvalidation_1-merror:0.200758\n",
            "[87]\tvalidation_0-merror:0.076389\tvalidation_1-merror:0.200758\n",
            "[88]\tvalidation_0-merror:0.075547\tvalidation_1-merror:0.200673\n",
            "[89]\tvalidation_0-merror:0.074979\tvalidation_1-merror:0.200758\n",
            "[90]\tvalidation_0-merror:0.073674\tvalidation_1-merror:0.200589\n",
            "[91]\tvalidation_0-merror:0.07319\tvalidation_1-merror:0.200842\n",
            "[92]\tvalidation_0-merror:0.073022\tvalidation_1-merror:0.200673\n",
            "[93]\tvalidation_0-merror:0.072601\tvalidation_1-merror:0.200337\n",
            "[94]\tvalidation_0-merror:0.072285\tvalidation_1-merror:0.200084\n",
            "[95]\tvalidation_0-merror:0.07178\tvalidation_1-merror:0.200084\n",
            "[96]\tvalidation_0-merror:0.071296\tvalidation_1-merror:0.2\n",
            "[97]\tvalidation_0-merror:0.070307\tvalidation_1-merror:0.199747\n",
            "[98]\tvalidation_0-merror:0.069444\tvalidation_1-merror:0.200505\n",
            "[99]\tvalidation_0-merror:0.068582\tvalidation_1-merror:0.200421\n",
            "[100]\tvalidation_0-merror:0.067487\tvalidation_1-merror:0.199579\n",
            "[101]\tvalidation_0-merror:0.067024\tvalidation_1-merror:0.199832\n",
            "[102]\tvalidation_0-merror:0.066288\tvalidation_1-merror:0.199411\n",
            "[103]\tvalidation_0-merror:0.065383\tvalidation_1-merror:0.200505\n",
            "[104]\tvalidation_0-merror:0.064457\tvalidation_1-merror:0.200505\n",
            "[105]\tvalidation_0-merror:0.063342\tvalidation_1-merror:0.200589\n",
            "[106]\tvalidation_0-merror:0.062626\tvalidation_1-merror:0.200505\n",
            "[107]\tvalidation_0-merror:0.062163\tvalidation_1-merror:0.201094\n",
            "[108]\tvalidation_0-merror:0.061827\tvalidation_1-merror:0.200421\n",
            "[109]\tvalidation_0-merror:0.060964\tvalidation_1-merror:0.199916\n",
            "[110]\tvalidation_0-merror:0.060438\tvalidation_1-merror:0.200926\n",
            "[111]\tvalidation_0-merror:0.059659\tvalidation_1-merror:0.200758\n",
            "[112]\tvalidation_0-merror:0.059175\tvalidation_1-merror:0.200842\n",
            "[113]\tvalidation_0-merror:0.058439\tvalidation_1-merror:0.200505\n",
            "[114]\tvalidation_0-merror:0.057449\tvalidation_1-merror:0.200589\n",
            "[115]\tvalidation_0-merror:0.057134\tvalidation_1-merror:0.201094\n",
            "[116]\tvalidation_0-merror:0.05665\tvalidation_1-merror:0.200926\n",
            "[117]\tvalidation_0-merror:0.056124\tvalidation_1-merror:0.199916\n",
            "[118]\tvalidation_0-merror:0.055556\tvalidation_1-merror:0.200505\n",
            "[119]\tvalidation_0-merror:0.054693\tvalidation_1-merror:0.200673\n",
            "[120]\tvalidation_0-merror:0.054061\tvalidation_1-merror:0.201347\n",
            "[121]\tvalidation_0-merror:0.05322\tvalidation_1-merror:0.20101\n",
            "[122]\tvalidation_0-merror:0.05282\tvalidation_1-merror:0.200842\n",
            "[123]\tvalidation_0-merror:0.052315\tvalidation_1-merror:0.201431\n",
            "[124]\tvalidation_0-merror:0.051515\tvalidation_1-merror:0.200505\n",
            "Stopping. Best iteration:\n",
            "[74]\tvalidation_0-merror:0.08891\tvalidation_1-merror:0.197896\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.5, max_delta_step=0, max_depth=7,\n",
              "              min_child_weight=1, missing=None, n_estimators=1000, n_jobs=-1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuW3rGPh8oeq",
        "colab_type": "code",
        "outputId": "d1bd57b8-439a-4da4-e0a7-82101671f9fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "results = model.evals_result()\n",
        "train_error = results['validation_0']['merror']\n",
        "val_error = results['validation_1']['merror']\n",
        "epoch = range(1, len(train_error)+1)\n",
        "plt.plot(epoch, train_error, label='Train')\n",
        "plt.plot(epoch, val_error, label='Validation')\n",
        "plt.ylabel('Classification Error')\n",
        "plt.xlabel('Model Complexity (n_estimators)')\n",
        "plt.ylim((0.18, 0.22)) # Zoom in\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAELCAYAAADOeWEXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZF7-ml6BhRRf"
      },
      "source": [
        "## Try adjusting these hyperparameters\n",
        "\n",
        "#### Random Forest\n",
        "- class_weight (for imbalanced classes)\n",
        "- max_depth (usually high, can try decreasing)\n",
        "- n_estimators (too low underfits, too high wastes time)\n",
        "- min_samples_leaf (increase if overfitting)\n",
        "- max_features (decrease for more diverse trees)\n",
        "\n",
        "#### Xgboost\n",
        "- scale_pos_weight (for imbalanced classes)\n",
        "- max_depth (usually low, can try increasing)\n",
        "- n_estimators (too low underfits, too high wastes time/overfits) — Use Early Stopping!\n",
        "- learning_rate (too low underfits, too high overfits)\n",
        "\n",
        "For more ideas, see [Notes on Parameter Tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html) and [DART booster](https://xgboost.readthedocs.io/en/latest/tutorials/dart.html)."
      ]
    }
  ]
}